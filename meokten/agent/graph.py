import json
import uuid
from typing import Any, Callable, List, Literal

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph
from pydantic import ValidationError

from agent.chains import answer_gen, query_check, query_gen
from agent.config import LLM, State, get_logger

# ë‚´ë¶€ ëª¨ë“ˆ import
from agent.tools import (
    create_tool_node_with_fallback,
    db_query_tool,
    get_schema_tool,
    list_tables_tool,
)

# ë¡œê¹… ì„¤ì • - graph.log íŒŒì¼ì— ë¡œê·¸ë¥¼ ë‚¨ê¹€
logger = get_logger()


# ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
class AgentGraph:
    def __init__(self):
        """SQL ì—ì´ì „íŠ¸ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        # ìƒˆ ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(State)
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("first_tool_call", self.first_tool_call)
        workflow.add_node(
            "list_tables_tool", create_tool_node_with_fallback([list_tables_tool])
        )

        # ê´€ë ¨ í…Œì´ë¸” ì„ íƒì„ ìœ„í•œ ëª¨ë¸ ë…¸ë“œ ì¶”ê°€
        self.model_get_schema = LLM().bind_tools([get_schema_tool])
        workflow.add_node(
            "model_get_schema",
            lambda state: {
                "messages": [self.model_get_schema.invoke(state["messages"])],
            },
        )

        workflow.add_node(
            "get_schema_tool", create_tool_node_with_fallback([get_schema_tool])
        )
        workflow.add_node("query_gen", self.query_gen_node)
        workflow.add_node("correct_query", self.model_check_query)
        workflow.add_node(
            "execute_query", create_tool_node_with_fallback([db_query_tool])
        )
        workflow.add_node("process_query_result", self.process_query_result)
        workflow.add_node("generate_answer", self.generate_answer_node)
        # ì—£ì§€ ì—°ê²°
        workflow.add_edge(START, "first_tool_call")
        workflow.add_edge("first_tool_call", "list_tables_tool")
        workflow.add_edge("list_tables_tool", "model_get_schema")
        workflow.add_edge("model_get_schema", "get_schema_tool")
        workflow.add_edge("get_schema_tool", "query_gen")
        workflow.add_conditional_edges("query_gen", self.should_continue)
        workflow.add_edge("correct_query", "execute_query")
        workflow.add_edge("execute_query", "process_query_result")
        workflow.add_edge("process_query_result", "query_gen")
        workflow.add_edge("generate_answer", END)

        # ê·¸ë˜í”„ ì»´íŒŒì¼
        self.app = workflow.compile(checkpointer=MemorySaver())

    # ì²« ë²ˆì§¸ ë„êµ¬ í˜¸ì¶œì„ ìœ„í•œ ë…¸ë“œ ì •ì˜
    def first_tool_call(self, state: State) -> dict[str, list[AIMessage]]:
        return {
            "messages": [
                AIMessage(
                    content="",
                    tool_calls=[
                        {
                            "name": "sql_db_list_tables",
                            "args": {},
                            "id": "initial_tool_call_abc123",
                        }
                    ],
                )
            ]
        }

    # ì¿¼ë¦¬ ì •í™•ì„± ì²´í¬ í•¨ìˆ˜
    def model_check_query(self, state: State) -> dict[str, list[AIMessage]]:
        """ì¿¼ë¦¬ ì •í™•ì„±ì„ ì²´í¬í•˜ëŠ” í•¨ìˆ˜"""
        return {"messages": [query_check.invoke({"messages": [state["messages"][-1]]})]}

    # ì¿¼ë¦¬ ìƒì„± ë…¸ë“œ ì •ì˜
    def query_gen_node(self, state: State):
        try:
            # ì´ì „ ë©”ì‹œì§€ì— ì´ë¯¸ ì¿¼ë¦¬ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            for message in reversed(state["messages"][:-1]):  # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì œì™¸
                if (
                    hasattr(message, "name")
                    and message.name == "db_query_tool"
                    and hasattr(message, "content")
                    and not message.content.startswith("Error:")
                ):
                    # ì¿¼ë¦¬ ê²°ê³¼ê°€ ìˆìœ¼ë©´ QUERY_EXECUTED_SUCCESSFULLY ë°˜í™˜
                    return {
                        "messages": [AIMessage(content="QUERY_EXECUTED_SUCCESSFULLY")]
                    }

            # ì¿¼ë¦¬ ìƒì„±
            message = query_gen.invoke(state)

            # ì´ë¯¸ ë‹µë³€ í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if (
                hasattr(message, "content")
                and isinstance(message.content, str)
                and len(message.content) > 50  # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë‹µë³€ìœ¼ë¡œ ê°„ì£¼
                and not message.content.startswith("SELECT")
                and not message.content.startswith("Error:")
            ):
                # ë‹µë³€ì´ "Answer:"ë¡œ ì‹œì‘í•˜ì§€ ì•Šìœ¼ë©´ ì¶”ê°€
                if not message.content.startswith("Answer:"):
                    message.content = f"Answer: {message.content}"
                return {"messages": [message]}

            # ì¼ë°˜ì ì¸ ì¿¼ë¦¬ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
            return {"messages": [message]}

        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "messages": [
                    AIMessage(
                        content=f"Error: ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    )
                ]
            }

    # ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ
    def process_query_result(self, state: State):
        last_message = state["messages"][-1]

        # ì¿¼ë¦¬ ì‹¤í–‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì„±ê³µ ì‹ í˜¸ ë°˜í™˜
        if (
            hasattr(last_message, "name")
            and last_message.name == "db_query_tool"
            and hasattr(last_message, "content")
            and not last_message.content.startswith("Error:")
        ):
            return {"messages": [AIMessage(content="QUERY_EXECUTED_SUCCESSFULLY")]}

        # ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        return {"messages": [last_message]}

    # ë‹µë³€ ìƒì„± ë…¸ë“œ ì •ì˜
    def generate_answer_node(self, state: State):
        try:
            # ì¿¼ë¦¬ ê²°ê³¼ ì°¾ê¸°
            query_result = None
            for message in reversed(state["messages"]):
                if (
                    hasattr(message, "name")
                    and message.name == "db_query_tool"
                    and hasattr(message, "content")
                    and not message.content.startswith("Error:")
                ):
                    query_result = message.content
                    break

            if not query_result:
                return {
                    "messages": [
                        AIMessage(
                            content="Answer: ì£„ì†¡í•©ë‹ˆë‹¤, ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                    ]
                }

            # ì‚¬ìš©ì ì§ˆë¬¸ ì°¾ê¸°
            user_question = None
            for message in state["messages"]:
                if hasattr(message, "type") and message.type == "human":
                    user_question = message.content
                    break

            # ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            try:
                # ë‹µë³€ ìƒì„± ì‹œë„
                answer_context = {
                    "messages": [
                        {
                            "role": "user",
                            "content": f"ì§ˆë¬¸: {user_question}\n\nì¿¼ë¦¬ ê²°ê³¼: {query_result}",
                        }
                    ]
                }

                # ì§ì ‘ LLM í˜¸ì¶œ í›„ ê²°ê³¼ ì²˜ë¦¬
                llm_response = answer_gen.invoke(
                    {"messages": answer_context["messages"]}
                )
                content = f"Answer: {llm_response}"
            except Exception as e:
                # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
                content = f"Answer: ì£„ì†¡í•©ë‹ˆë‹¤, ì¿¼ë¦¬ ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

            return {"messages": [AIMessage(content=content)]}

        except Exception as e:
            return {
                "messages": [
                    AIMessage(
                        content=f"Answer: ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    )
                ]
            }

    # ì¡°ê±´ë¶€ ì—£ì§€ ì •ì˜
    def should_continue(
        self,
        state: State,
    ) -> Literal[END, "correct_query", "query_gen", "generate_answer"]:
        last_message = state["messages"][-1]

        # ë©”ì‹œì§€ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°
        if hasattr(last_message, "content") and isinstance(last_message.content, str):
            # 1) Terminate if the message starts with "Answer:"
            if last_message.content.startswith("Answer:"):
                return END
            # 2) ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìœ¼ë©´ ë‹µë³€ ìƒì„± ë…¸ë“œë¡œ ì´ë™
            elif last_message.content == "QUERY_EXECUTED_SUCCESSFULLY":
                return "generate_answer"
            # 3) ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì¿¼ë¦¬ ìƒì„± ë…¸ë“œë¡œ ëŒì•„ê°
            elif last_message.content.startswith("Error:"):
                return "query_gen"
            # 4) ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì´ ìˆìœ¼ë©´ (ì˜ì–´ë¡œ ëœ ë‹µë³€ ë“±) ì¢…ë£Œ
            elif len(last_message.content) > 20 and not last_message.content.startswith(
                "SELECT"
            ):
                return END

        # 5) ë°˜ë³µ íšŸìˆ˜ ì œí•œì„ ìœ„í•œ ì•ˆì „ì¥ì¹˜
        if len(state["messages"]) > 20:
            return END

        # ê¸°ë³¸ì ìœ¼ë¡œ ì¿¼ë¦¬ ê²€ì¦ ë…¸ë“œë¡œ ì´ë™
        return "correct_query"

    def random_uuid(self):
        """ëœë¤ UUIDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return str(uuid.uuid4())

    def invoke_graph(
        self,
        graph: Any,
        inputs: dict,
        config: RunnableConfig = None,
        node_names: List[str] = [],
        callback: Callable = None,
        return_result: bool = True,
    ):
        """
        LangGraph ì•±ì˜ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì˜ˆì˜ê²Œ ìŠ¤íŠ¸ë¦¬ë°í•˜ì—¬ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

        Args:
            graph: ì‹¤í–‰í•  ì»´íŒŒì¼ëœ LangGraph ê°ì²´
            inputs (dict): ê·¸ë˜í”„ì— ì „ë‹¬í•  ì…ë ¥ê°’ ë”•ì…”ë„ˆë¦¬
            config (RunnableConfig, optional): ì‹¤í–‰ ì„¤ì •
            node_names (List[str], optional): ì¶œë ¥í•  ë…¸ë“œ ì´ë¦„ ëª©ë¡. ê¸°ë³¸ê°’ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸
            callback (Callable, optional): ê° ì²­í¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜. ê¸°ë³¸ê°’ì€ None
                ì½œë°± í•¨ìˆ˜ëŠ” {"node": str, "content": str} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
            return_result (bool, optional): ê²°ê³¼ë¥¼ ë°˜í™˜í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ True

        Returns:
            dict or None: return_resultê°€ Trueì¸ ê²½ìš° ìµœì¢… ê²°ê³¼ë¥¼ ë°˜í™˜, ì•„ë‹ˆë©´ None ë°˜í™˜
        """
        if config is None:
            config = RunnableConfig(
                recursion_limit=30, configurable={"thread_id": self.random_uuid()}
            )

        def format_namespace(namespace):
            return namespace[-1].split(":")[0] if len(namespace) > 0 else "root graph"

        # ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜
        result = {}

        # subgraphs=True ë¥¼ í†µí•´ ì„œë¸Œê·¸ë˜í”„ì˜ ì¶œë ¥ë„ í¬í•¨
        for namespace, chunk in graph.stream(
            inputs, config, stream_mode="updates", subgraphs=True
        ):
            for node_name, node_chunk in chunk.items():
                # node_namesê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ í•„í„°ë§
                if len(node_names) > 0 and node_name not in node_names:
                    continue

                # ê²°ê³¼ ì €ì¥ (return_resultê°€ Trueì¸ ê²½ìš°)
                if return_result:
                    if node_name not in result:
                        result[node_name] = []
                    result[node_name].append(node_chunk)

                # ì½œë°± í•¨ìˆ˜ê°€ ìˆëŠ” ê²½ìš° ì‹¤í–‰
                if callback is not None:
                    callback({"node": node_name, "content": node_chunk})
                # ì½œë°±ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
                else:
                    logger.debug("\n" + "=" * 50)
                    formatted_namespace = format_namespace(namespace)
                    if formatted_namespace == "root graph":
                        logger.debug(f"ğŸ”„ Node: {node_name} ğŸ”„")
                    else:
                        logger.debug(
                            f"ğŸ”„ Node: {node_name} in [{formatted_namespace}] ğŸ”„"
                        )
                    logger.debug("- " * 25)

                    # ë…¸ë“œì˜ ì²­í¬ ë°ì´í„° ì¶œë ¥
                    if isinstance(node_chunk, dict):
                        for k, v in node_chunk.items():
                            if isinstance(v, BaseMessage):
                                logger.debug(f"{v}")
                            elif isinstance(v, list):
                                for list_item in v:
                                    if isinstance(list_item, BaseMessage):
                                        logger.debug(f"{list_item}")
                                    else:
                                        logger.debug(f"{list_item}")
                            elif isinstance(v, dict):
                                for (
                                    node_chunk_key,
                                    node_chunk_value,
                                ) in node_chunk.items():
                                    logger.debug(
                                        f"{node_chunk_key}:\n{node_chunk_value}"
                                    )
                            else:
                                logger.debug(f"{k}:\n{v}")
                    else:
                        if node_chunk is not None:
                            for item in node_chunk:
                                logger.debug(f"{item}")
                    logger.debug("=" * 50)

        # ìµœì¢… ê²°ê³¼ ë°˜í™˜ (return_resultê°€ Trueì¸ ê²½ìš°)
        if return_result:
            # ê·¸ë˜í”„ì˜ ìµœì¢… ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            full_result = graph.invoke(inputs, config)

            # ìµœì¢… ê²°ê³¼ì—ì„œ "Answer:"ë¡œ ì‹œì‘í•˜ëŠ” ë§ˆì§€ë§‰ ë©”ì‹œì§€ ë˜ëŠ” SubmitFinalAnswer ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ì¶”ì¶œ
            final_result = {"messages": []}
            if "messages" in full_result:
                # 1. "Answer:"ë¡œ ì‹œì‘í•˜ëŠ” ë©”ì‹œì§€ ì°¾ê¸°
                for message in reversed(full_result["messages"]):
                    if (
                        hasattr(message, "content")
                        and isinstance(message.content, str)
                        and message.content.startswith("Answer:")
                    ):
                        final_result["messages"] = [message]
                        break

                # 2. ìµœì¢… ë‹µë³€ì´ ì—†ëŠ” ê²½ìš° SubmitFinalAnswer ë„êµ¬ í˜¸ì¶œ ê²°ê³¼ ì°¾ê¸°
                if not final_result["messages"]:
                    for message in reversed(full_result["messages"]):
                        if hasattr(message, "tool_calls") and message.tool_calls:
                            for tc in message.tool_calls:
                                if tc.get("name") == "SubmitFinalAnswer":
                                    # ë‹¤ìŒ ë©”ì‹œì§€ê°€ ìµœì¢… ë‹µë³€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                                    idx = full_result["messages"].index(message)
                                    if idx + 1 < len(full_result["messages"]):
                                        final_result["messages"] = [
                                            full_result["messages"][idx + 1]
                                        ]
                                        break
                            if final_result["messages"]:
                                break

                # 3. ì—¬ì „íˆ ìµœì¢… ë‹µë³€ì´ ì—†ëŠ” ê²½ìš° ì›ë˜ ê²°ê³¼ ì‚¬ìš©
                if not final_result["messages"]:
                    final_result = full_result
            else:
                final_result = full_result

            return {"streaming_results": result, "final_result": final_result}

        return None

    def run_agent(
        self,
        query: str,
    ):
        """
        ì‚¬ìš©ì ì§ˆì˜ë¥¼ ë°›ì•„ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            query (str): ì‚¬ìš©ì ì§ˆì˜
            agent_graph: ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)

        Returns:
            dict: ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼
        """
        try:

            # ì—ì´ì „íŠ¸ ì‹¤í–‰
            logger.info(f"ì—ì´ì „íŠ¸ ì‹¤í–‰: {query}")
            result = self.invoke_graph(
                graph=self.app,
                inputs={"messages": [HumanMessage(content=query)]},
                config=RunnableConfig(
                    recursion_limit=30, configurable={"thread_id": self.random_uuid()}
                ),
                return_result=True,
            )

            # ê²°ê³¼ ì²˜ë¦¬
            if (
                result
                and "final_result" in result
                and "messages" in result["final_result"]
            ):
                messages = result["final_result"]["messages"][0].content
                logger.info(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼: {messages}")
                return messages

        except Exception as e:
            logger.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
